{
    "run_id": "20250510_022315_train",
    "timestamp": "2025-05-10T02:23:15.356002",
    "model_type": "blstm",
    "preprocessing_info": {
        "directory": "processed\\train\\latest",
        "run_id": "20250510_015047_preprocess",
        "timestamp": "2025-05-10T01:50:47.823882",
        "sample_count": 2535
    },
    "config": {
        "test_size": 0.2,
        "random_state": 42,
        "model_specific": {
            "blstm_mfcc_count": 13,
            "lstm_units": 64,
            "dropout_rate": 0.3,
            "learning_rate": 0.001,
            "batch_size": 64,
            "epochs": 50
        }
    },
    "system_info": {
        "platform": "Windows-10-10.0.19045-SP0",
        "python_version": "3.9.13",
        "cpu_count": 4,
        "use_gpu_config": true,
        "gpu_available": false
    },
    "performance": {
        "accuracy": 0.9684418145956607,
        "training_time": 168.0744822025299,
        "class_report": {
            "Abdulbasit Abdulsamad": {
                "precision": 1.0,
                "recall": 0.9803921568627451,
                "f1-score": 0.9900990099009901,
                "support": 102.0
            },
            "Mahmoud Khalil Al-Hussary": {
                "precision": 0.9509803921568627,
                "recall": 0.9603960396039604,
                "f1-score": 0.9556650246305419,
                "support": 101.0
            },
            "Mishary Alafasi": {
                "precision": 0.9702970297029703,
                "recall": 0.9702970297029703,
                "f1-score": 0.9702970297029703,
                "support": 101.0
            },
            "Mohammed Siddiq Al-Minshawi": {
                "precision": 0.941747572815534,
                "recall": 0.9509803921568627,
                "f1-score": 0.9463414634146341,
                "support": 102.0
            },
            "Saud Al-Shuraim": {
                "precision": 0.9801980198019802,
                "recall": 0.9801980198019802,
                "f1-score": 0.9801980198019802,
                "support": 101.0
            },
            "accuracy": 0.9684418145956607,
            "macro avg": {
                "precision": 0.9686446028954695,
                "recall": 0.9684527276257038,
                "f1-score": 0.9685201094902233,
                "support": 507.0
            },
            "weighted avg": {
                "precision": 0.9686533965187921,
                "recall": 0.9684418145956607,
                "f1-score": 0.968518926559918,
                "support": 507.0
            }
        }
    },
    "total_time": 169.044438123703
}