{
    "run_id": "20250419_010603_train",
    "timestamp": "2025-04-19T01:06:03.390206",
    "model_type": "blstm",
    "preprocessing_info": {
        "directory": "/content/processed/train/20250419_001638_preprocess",
        "run_id": "20250419_001638_preprocess",
        "timestamp": "2025-04-19T00:16:38.312528",
        "sample_count": 4056
    },
    "config": {
        "test_size": 0.2,
        "random_state": 42,
        "model_specific": {
            "blstm_mfcc_count": 13,
            "lstm_units": 64,
            "dropout_rate": 0.3,
            "learning_rate": 0.001,
            "batch_size": 64,
            "epochs": 50
        }
    },
    "system_info": {
        "platform": "Linux-6.1.123+-x86_64-with-glibc2.35",
        "python_version": "3.11.12",
        "cpu_count": 2,
        "use_gpu_config": true,
        "gpu_available": true
    },
    "performance": {
        "accuracy": 0.9766009852216748,
        "training_time": 28.991318225860596,
        "class_report": {
            "Abdulbasit Abdulsamad": {
                "precision": 0.9757281553398058,
                "recall": 0.9901477832512315,
                "f1-score": 0.9828850855745721,
                "support": 203.0
            },
            "Mahmoud Khalil Al-Hussary": {
                "precision": 0.95260663507109,
                "recall": 0.9901477832512315,
                "f1-score": 0.9710144927536232,
                "support": 203.0
            },
            "Mishary Alafasi": {
                "precision": 0.9900990099009901,
                "recall": 0.9803921568627451,
                "f1-score": 0.9852216748768473,
                "support": 102.0
            },
            "Mohammed Siddiq Al-Minshawi": {
                "precision": 0.9896373056994818,
                "recall": 0.9408866995073891,
                "f1-score": 0.9646464646464646,
                "support": 203.0
            },
            "Saud Al-Shuraim": {
                "precision": 0.9900990099009901,
                "recall": 0.9900990099009901,
                "f1-score": 0.9900990099009901,
                "support": 101.0
            },
            "accuracy": 0.9766009852216748,
            "macro avg": {
                "precision": 0.9796340231824715,
                "recall": 0.9783346865547176,
                "f1-score": 0.9787733455504994,
                "support": 812.0
            },
            "weighted avg": {
                "precision": 0.9770177765028418,
                "recall": 0.9766009852216748,
                "f1-score": 0.9765485930557812,
                "support": 812.0
            }
        }
    },
    "total_time": 29.79589319229126
}