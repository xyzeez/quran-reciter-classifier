{
    "run_id": "20250624_000444_train",
    "timestamp": "2025-06-24T00:04:44.167748",
    "model_type": "random_forest",
    "preprocessing_info": {
        "directory": "processed\\train\\latest",
        "run_id": "20250623_222223_preprocess",
        "timestamp": "2025-06-23T22:22:23.013267",
        "sample_count": 24444
    },
    "config": {
        "test_size": 0.2,
        "random_state": 42,
        "model_specific": {
            "n_estimators": 100,
            "max_depth": 10,
            "n_folds": 5
        }
    },
    "system_info": {
        "platform": "Windows-10-10.0.26100-SP0",
        "python_version": "3.10.0",
        "cpu_count": 20,
        "use_gpu_config": true,
        "gpu_available": false
    },
    "performance": {
        "accuracy": 0.9985682143587645,
        "training_time": 10.381505250930786,
        "class_report": {
            "Abdulbasit Abdulsamad": {
                "precision": 0.9979402677651905,
                "recall": 0.9989690721649485,
                "f1-score": 0.9984544049459042,
                "support": 970.0
            },
            "Abdulrahman Alsudaes": {
                "precision": 1.0,
                "recall": 1.0,
                "f1-score": 1.0,
                "support": 973.0
            },
            "Ahmad Al-Ajmy": {
                "precision": 1.0,
                "recall": 1.0,
                "f1-score": 1.0,
                "support": 974.0
            },
            "Maher Al Meaqli": {
                "precision": 0.9958974358974358,
                "recall": 0.9989711934156379,
                "f1-score": 0.997431946584489,
                "support": 972.0
            },
            "Yasser Al-Dosari": {
                "precision": 0.998995983935743,
                "recall": 0.995,
                "f1-score": 0.996993987975952,
                "support": 1000.0
            },
            "accuracy": 0.9985682143587645,
            "macro avg": {
                "precision": 0.9985667375196737,
                "recall": 0.9985880531161172,
                "f1-score": 0.9985760679012688,
                "support": 4889.0
            },
            "weighted avg": {
                "precision": 0.9985703316343394,
                "recall": 0.9985682143587645,
                "f1-score": 0.9985679306307225,
                "support": 4889.0
            }
        }
    },
    "total_time": 11.259066104888916
}